{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean_TTS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GAjjZleecmdj",
        "jJ4Q3D7mcr1M"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quynhu-d/TTS_FastSpeech/blob/overfit_batch/Clean_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlIPcJK8Esan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e4ddd4-4fb7-425a-8745-2e991c08372d"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAjjZleecmdj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8afGpXDIdPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6569cc-001d-4bf6-8d56-b95b255a6773"
      },
      "source": [
        "!git clone https://github.com/quynhu-d/TTS_FastSpeech"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TTS_FastSpeech'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 43 (delta 6), reused 41 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCoaEmsL3zNE",
        "outputId": "2502b26d-66b5-4b2d-a467-0c6ed0380923"
      },
      "source": [
        "%cd TTS_FastSpeech/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TTS_FastSpeech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgiO1Oi53tZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e22e08-5123-403a-a2e6-f37d7b199b63"
      },
      "source": [
        "!pip install -r ./requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 3)) (4.62.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 4)) (1.1.5)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 7)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 8)) (0.10.0+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r ./requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (2.1.9)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (0.10.3.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r ./requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->-r ./requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->-r ./requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->-r ./requirements.txt (line 1)) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa->-r ./requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->-r ./requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->-r ./requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r ./requirements.txt (line 1)) (2.21)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r ./requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r ./requirements.txt (line 4)) (2018.9)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r ./requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r ./requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r ./requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r ./requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r ./requirements.txt (line 5)) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 44.0 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r ./requirements.txt (line 5)) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r ./requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r ./requirements.txt (line 5)) (1.1.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->-r ./requirements.txt (line 6)) (0.3.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r ./requirements.txt (line 6)) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->-r ./requirements.txt (line 6)) (4.8.2)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r ./requirements.txt (line 6)) (3.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r ./requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r ./requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r ./requirements.txt (line 6)) (21.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r ./requirements.txt (line 6)) (2.0.8)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->-r ./requirements.txt (line 6)) (3.6.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=468e7ffe2d58affb7edddcc24027ec2a938632bc30e4e922e40c9b45efb8b539\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=1a24a8f65599ef9c366ab33f5e36f8b4f548c2877e7a05f3accd090d629287f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, gitdb, fsspec, aiohttp, yaspin, xxhash, subprocess32, shortuuid, sentry-sdk, pathtools, huggingface-hub, GitPython, docker-pycreds, configparser, wandb, datasets\n",
            "Successfully installed GitPython-3.1.24 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 configparser-5.1.0 datasets-1.16.1 docker-pycreds-0.4.0 frozenlist-1.2.0 fsspec-2021.11.1 gitdb-4.0.9 huggingface-hub-0.1.2 multidict-5.2.0 pathtools-0.1.2 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.7 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n1yy7Mc4DpA"
      },
      "source": [
        "from model import FastSpeech, FastSpeechConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ4Q3D7mcr1M"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtFsl61G5ltv"
      },
      "source": [
        "from data.lj_dataset import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moA-Wk07503w"
      },
      "source": [
        "from data.data_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIyKo6ah6crj",
        "outputId": "06a481a2-51b6-45a6-eb6d-bb813e1d0dbc"
      },
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar -xjf LJSpeech-1.1.tar.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 15:22:32--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
            "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [application/octet-stream]\n",
            "Saving to: ‘LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "LJSpeech-1.1.tar.bz 100%[===================>]   2.56G  90.6MB/s    in 38s     \n",
            "\n",
            "2021-12-01 15:23:10 (69.0 MB/s) - ‘LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdJdUKe-53dQ"
      },
      "source": [
        "from typing import Tuple, Dict, Optional, List, Union\n",
        "from itertools import islice\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6FNQhf8YLZ"
      },
      "source": [
        "from featurizer.mel_config import *\n",
        "from featurizer.mel_spectrogram import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2m1ajaecvro"
      },
      "source": [
        "# Model\n",
        "Параметры в основном такие же, как в статье, но пока позьмём модель чуть поменьше, с трансформерами по 3 блока в энкодере и декодере (вместо 6)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtQr08TG4bsA",
        "outputId": "d717d367-bfb3-4f8d-85d8-a3ad7be99bc2"
      },
      "source": [
        "# Fast Speech model configuration\n",
        "fconfig = FastSpeechConfig()\n",
        "fconfig.d_model = 384\n",
        "fconfig.d_k = 384\n",
        "fconfig.d_v = 384\n",
        "fconfig.n_dec = fconfig.n_enc = 3\n",
        "print(fconfig)\n",
        "fs_model = FastSpeech(51, fconfig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSpeechConfig(d_model=384, conv_hid_sz=1536, kernel_sz=3, d_k=384, d_v=384, dropout_rate=0.1, n_enc=3, n_dec=3, n_heads=2, max_phoneme_len=5000, max_mel_len=5000, n_mels=80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPU4fPU_mdbm"
      },
      "source": [
        "device = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAGvD-UamPrX"
      },
      "source": [
        "## Vocoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6vd0PAkheXJ",
        "outputId": "2ae963fd-f73a-43bc-80a3-6bc80ac1e07b"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/waveglow.git\n",
        "!pip install googledrivedownloader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'waveglow'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Total 190 (delta 0), reused 0 (delta 0), pack-reused 190\u001b[K\n",
            "Receiving objects: 100% (190/190), 435.41 KiB | 4.11 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX5wQ5uAhkFU",
        "outputId": "f93584de-18a7-448b-a251-b4407af17024"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(\n",
        "    file_id='1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF',\n",
        "    dest_path='./waveglow_256channels_universal_v5.pt'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF into ./waveglow_256channels_universal_v5.pt... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77DymjmDhohi"
      },
      "source": [
        "# import warnings\n",
        "# import sys\n",
        "# sys.path.append('waveglow/')\n",
        "\n",
        "# warnings.filterwarnings('ignore')\n",
        "import torch.nn as nn\n",
        "\n",
        "class Vocoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Vocoder, self).__init__()\n",
        "\n",
        "        model = torch.load('../waveglow_256channels_universal_v5.pt', map_location='cpu')[\n",
        "            'model']\n",
        "        self.net = model.remove_weightnorm(model)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def inference(self, spect: torch.Tensor):\n",
        "        spect = self.net.upsample(spect)\n",
        "\n",
        "        # trim the conv artifacts\n",
        "        time_cutoff = self.net.upsample.kernel_size[0] - \\\n",
        "            self.net.upsample.stride[0]\n",
        "        spect = spect[:, :, :-time_cutoff]\n",
        "\n",
        "        spect = spect.unfold(2, self.net.n_group, self.net.n_group) \\\n",
        "            .permute(0, 2, 1, 3) \\\n",
        "            .contiguous() \\\n",
        "            .flatten(start_dim=2) \\\n",
        "            .transpose(-1, -2)\n",
        "\n",
        "        # generate prior\n",
        "        audio = torch.randn(spect.size(0), self.net.n_remaining_channels, spect.size(-1)) \\\n",
        "            .to(spect.device)\n",
        "\n",
        "        for k in reversed(range(self.net.n_flows)):\n",
        "            n_half = int(audio.size(1) / 2)\n",
        "            audio_0 = audio[:, :n_half, :]\n",
        "            audio_1 = audio[:, n_half:, :]\n",
        "\n",
        "            output = self.net.WN[k]((audio_0, spect))\n",
        "\n",
        "            s = output[:, n_half:, :]\n",
        "            b = output[:, :n_half, :]\n",
        "            audio_1 = (audio_1 - b) / torch.exp(s)\n",
        "            audio = torch.cat([audio_0, audio_1], 1)\n",
        "\n",
        "            audio = self.net.convinv[k](audio, reverse=True)\n",
        "\n",
        "            if k % self.net.n_early_every == 0 and k > 0:\n",
        "                z = torch.randn(\n",
        "                    spect.size(0), self.net.n_early_size, spect.size(2),\n",
        "                    device=spect.device\n",
        "                )\n",
        "                audio = torch.cat((z, audio), 1)\n",
        "\n",
        "        audio = audio.permute(0, 2, 1) \\\n",
        "            .contiguous() \\\n",
        "            .view(audio.size(0), -1)\n",
        "\n",
        "        return audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4dCluxyhtBG",
        "outputId": "8b74a3d3-15c9-45c0-e748-10b54b4b3b83"
      },
      "source": [
        "%cd waveglow/\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vocoder = Vocoder().to(device).eval()\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'waveglow/'\n",
            "/content/TTS_FastSpeech/waveglow\n",
            "/content/TTS_FastSpeech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYe7akCLG5XI"
      },
      "source": [
        "# Overfitting\n",
        "\n",
        "Оптимизатор -- Adam с параметрами для трансформеров (без планировщика)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn5IL5pnG7jS"
      },
      "source": [
        "dataset = LJSpeechDataset('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrCF1z0xG9wS"
      },
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=3, collate_fn=LJSpeechCollator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNxm6OaHXT1"
      },
      "source": [
        "iter(train_dataloader).next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L38Hy6l0g95j",
        "outputId": "3fd039ab-571e-42cb-f7bf-e583beede16f"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquynhu_d\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_VsxSVblHSfB",
        "outputId": "fee4ca4e-955d-42cd-ba15-4f63fbe07dc3"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from model.aligner import GraphemeAligner\n",
        "from model.fastspeech import FastSpeech\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FastSpeech(51, fconfig).to(device)\n",
        "print(model)\n",
        "aligner = GraphemeAligner().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 3e-4, (.9,.98))\n",
        "n_epochs = 30000\n",
        "wandb.init(name='overfit_batch')\n",
        "featurizer = MelSpectrogram(MelSpectrogramConfig()).to(device)\n",
        "for i in range(n_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        batch.mel = featurizer(batch.waveform)\n",
        "        durations = aligner(batch.waveform, batch.waveform_length, batch.transcript)\n",
        "        durations *= batch.mel.size(-1)\n",
        "        batch.durations = durations.round()\n",
        "        batch.to(device)\n",
        "        output = model(batch)\n",
        "        batch.to(device)\n",
        "        # print(batch.duration_preds.sum(1), batch.mel.size(-1), batch.durations.sum(1))\n",
        "        dp_loss = F.mse_loss(batch.duration_preds, batch.durations)\n",
        "        print(output.size(), batch.mel.size())\n",
        "        sz_diff = np.abs(batch.mel.size(-1) - output.size(-1))\n",
        "        if batch.mel.size(-1) > output.size(-1):\n",
        "            print('padding batch')\n",
        "            output = F.pad(output, (0, sz_diff, 0, 0, 0, 0), \"constant\", MelSpectrogramConfig.pad_value)\n",
        "        else:\n",
        "            print('padding mel')\n",
        "            batch.mel = F.pad(batch.mel, (0, sz_diff, 0, 0, 0, 0), \"constant\", MelSpectrogramConfig.pad_value)        \n",
        "        print(batch.mel.shape, output.shape)\n",
        "        mel_loss = F.mse_loss(output, batch.mel)\n",
        "        loss = mel_loss + dp_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        wav = vocoder.inference(output.to(device))\n",
        "        idx = np.random.randint(batch.mel.shape[0])\n",
        "        wandb.log({\n",
        "            'loss': loss,\n",
        "            'mel_loss': mel_loss,\n",
        "            'dp_loss': dp_loss,\n",
        "            'mel': wandb.Image(batch.mel[idx]),\n",
        "            'mel_pred': wandb.Image(output[idx]),\n",
        "            'audio': wandb.Audio(batch.waveform[idx].detach().cpu().numpy(), sample_rate=MelSpectrogramConfig.sr),\n",
        "            'audio_pred': wandb.Audio(wav[idx].detach().cpu().numpy(), sample_rate=MelSpectrogramConfig.sr),\n",
        "            'step': i\n",
        "        })\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastSpeech(\n",
            "  (emb_encoder): Embedding(51, 384)\n",
            "  (phoneme_pe): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (phoneme_fft): Sequential(\n",
            "    (0): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (len_reg): LengthRegulator(\n",
            "    (dur_pred): DurationPredictor(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (out): Linear(in_features=384, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mel_pe): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (mel_fft): Sequential(\n",
            "    (0): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): FFTBlock(\n",
            "      (pre_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): MultiHeadAttention(\n",
            "        (att_heads): ModuleList(\n",
            "          (0): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "          (1): SelfAttention(\n",
            "            (wq): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wk): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (wv): Linear(in_features=384, out_features=384, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (w_out): Linear(in_features=768, out_features=384, bias=True)\n",
            "      )\n",
            "      (att_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): Sequential(\n",
            "        (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (1): ReLU()\n",
            "        (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=same)\n",
            "        (3): ReLU()\n",
            "      )\n",
            "      (conv_ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=384, out_features=80, bias=True)\n",
            ")\n",
            "torch.Size([3, 80, 800]) torch.Size([3, 80, 833])\n",
            "padding batch\n",
            "torch.Size([3, 80, 833]) torch.Size([3, 80, 833])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1217d20d1f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# wandb.log({\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-833fecec4b41>\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, spect)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvinv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_early_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TTS_FastSpeech/waveglow/glow.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, reverse)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'W_inverse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# Reverse computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mW_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mW_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_inverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'torch.cuda.HalfTensor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}